[DEFAULT]
# Adjust paths to your project structure
root_dir = /Users/kexin/ModalityEnvProjects/TALS_analysis_pipeline/
 # CHANGE THIS
data_dir = %(root_dir)s/
# CHANGE THIS (where final_aggregated_data.csv and final_participants.csv will live)
output_dir = %(root_dir)s/output
 # CHANGE THIS (where results and logs will be saved)
# This should point to your *project-specific* utils file created in step 2
utils_package = %(root_dir)s/ALS_project_utils.py
 # CHANGE THIS
# nemsi_dir might not be needed if analysis_utils.py is in the python path or same dir as notebook
# If analysis_utils.py is elsewhere, ensure it's discoverable. Or adjust if pipeline uses this path.
nemsi_dir = /path/to/where/analysis_utils/lives
 # CHANGE THIS IF NEEDED

[data]
# Point to the consolidated data file created in step 1b
data_file = %(data_dir)s/final_aggregated_data.csv
# UPDATED
# Point to the *original* data_aggregated.csv IF it's only used for metric *types* (speech, facial)
# OR create a new reference file including your NEW metrics if needed for column selection/aggregation.
# If unsure, start with the original, but be aware new metrics might not be automatically handled by all functions.
metrics_per_task_ref = ./MetricsPerTaskReference.csv
 # REVIEW/CHANGE THIS
# Decide if new metrics should be averaged across tasks (likely 'no')
aggregate_metrics_across_all_prompts = no
# REVIEW/CHANGE THIS
# Set as needed for cross-sectional analysis
nth_session_for_X_sectional = first
# Update exclusion lists if necessary for your combined dataset
sessions_to_exclude = [] 
# REVIEW/CHANGE THIS
access_codes_to_exclude = [] 
# REVIEW/CHANGE THIS
# Adjust threshold for dropping metrics with too many NaNs
threshold_for_deleting_metrics = 0.05
# REVIEW/CHANGE THIS (Example: allow up to 10% missing)
# Set based on whether you want listwise deletion *before* analyses
remove_missing_values_for_all_analyses = no
# REVIEW/CHANGE THIS
#session_ids_for_analysis = %(data_dir)s/session_ids_Xsec_aggr.txt # Uncomment and provide file if needed

# VERY IMPORTANT: Review columns to drop. Ensure your NEW metrics are NOT dropped.
# Remove generic patterns if they clash with your new metric names.
metric_columns_to_drop = [
    'EXCLUDE',
    'head_tilt',
    'right',
    'left',
    '.*_R_.*',
    '.*_L_.*',
    'JC_max',
    'JC_min',
    'LL_max',
    'LL_min',
    'LL_avg',
    'JC_avg',
    'metrics_ADL',
    'SIT',
    'facial_metrics.*jJC',
    'facial_metrics.*aJC',
    'facial_metrics.*aLL',
    'facial_metrics.*jLL',
    'dominant_hand_(velocity|acceleration|jerk)$',
    'jitter',
    'shimmer',
    '_path_',
    'volume',
    'ICD_px',
    'ID_px',
    'articulation',
    'min_f0',
    'max_f0',
    'intensity',
    'ID_mm',
    'ICD_mm',
    '.*abs_min',
    'Utterance_dur',
    'open_min',
    'Counting',
    '.*ThreeStepTask.*',
    '.*transcription.*', # Keep if needed by any step, otherwise remove
    '.*CameraCalibration.*',
    #'Phonation', # Keep specific phonation tasks if needed
    'SpeakingSalivatingSwallowing',
    'snr', # Be specific if dropping only certain SNR metrics
    '_icd_', # Review if needed
    'EMPATH', # Keep if needed
    'TurnTutorial',
    # The cognitive pattern might be okay if you are not analyzing those standard cog metrics
    '.*(?<!cognitive_metrics_)(RecallCAPTCHA|DelayedRecall|ImmediateRecall|DigitSpan|CategoryFluency)',
    'PROP' # Keep if needed
    # Add patterns here to drop OLD metrics you *don't* want from the combined file
    ] # REVIEW/CHANGE THIS THOROUGHLY

# Update if any metrics need time-based exclusion
metrics_to_drop_for_certain_time_periods = {}
 # REVIEW/CHANGE THIS
# Enable if you want age/sex matched controls selected
use_balanced_data = yes
 # REVIEW/CHANGE THIS
# Set number of folds for cross-validation if used
kfold_n = 5
# project_code_to_spacy_model = {
#     72: 'es_core_news_sm',
#     74: 'es_core_news_sm',
#     70: 'en_core_web_sm',
#     71: 'en_core_web_sm'
# }

project_code_to_spacy_model = {"72": "es_core_news_sm", "74": "es_core_news_sm", "70": "en_core_web_sm", "71": "en_core_web_sm"}
[surveys]
# Keep your existing binary_classification_target etc.
# Comment out or keep the original single regression_target for potential use elsewhere,
# but the code below will prioritize the list if it exists.
# regression_target = survey_response_scores_ALSFRSR_6

# NEW: List of regression targets for correlation analysis loop
# Use Python list syntax
regression_targets_list = ['survey_response_scores_ALSFRSR_5_1', 'survey_response_scores_ALSFRSR_6', 'survey_response_scores_ALSFRSR_7']
regression_target = survey_response_scores_ALSFRSR_6
binary_classification_target = demo_patient_flag
[demographics]
# Point to the demographics file created in step 1a
demographics_file = %(data_dir)s/final_participants.csv
 # UPDATED
# Set the column name in final_participants.csv that contains the unique participant ID
user_key = access_code
 # UPDATED (must match column name in final_participants.csv)
# Threshold for ignoring potentially incorrect birth years
ignore_age_threshold = 15
# Column in final_participants.csv indicating patient status BEFORE cohort assignment
patient_indicator_column = cohort_raw
 # UPDATED (must match column name in final_participants.csv)
# Value in the patient_indicator_column that signifies a patient
patient_indicator_value = Patient
 # UPDATED (must match value used in final_participants.csv)
# Number of final cohorts defined by assign_cohort (e.g., Patient, Control = 2)
num_cohorts = 2 # REVIEW/CHANGE THIS

[output]
# Optional: change default color for plots
default_graph_color = "#CC6633"
